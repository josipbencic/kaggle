{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/josipbencic/kaggle/blob/master/predict_future_sales_josip.ipynb",
      "authorship_tag": "ABX9TyMmaUpz7Uu8mXxAZcpGTP1d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josipbencic/kaggle/blob/master/predict_future_sales_josip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qha1WQzF1Gh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df3d5976-66d9-49c2-97c4-6d7ef8b3ec30"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "PROJECT_PATH = \"/content/drive/My Drive/kaggle_tmp\"\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "\n",
        "GIT_TOKEN = \"13b32b3481c45a9a7bdd7f223644aa47b1156c42\"\n",
        "GIT_USERNAME = \"josipbencic\"\n",
        "GIT_REPOSITORY = \"kaggle\"\n",
        "\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "\n",
        "!git clone \"{GIT_PATH}\" ./temp      # clone github repository to temp folder\n",
        "!mv ./temp/* \"{PROJECT_PATH}\"       # move all files/folders in temp folder to folder defined in project path\n",
        "!rm -rf ./temp                      # remove all the files/folders in temp folder\n",
        "#!rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./   # use remote sync to copy from google drive to local runtime google colab\n",
        "                                                     # but exclude data folder                                          \n",
        "!rsync -aP \"{PROJECT_PATH}\"/*  ./\n",
        "\n",
        "!pip install category_encoders\n",
        "\n",
        "## Inspect collab machine\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "#import GPUtil as GPU\n",
        "#GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "#gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " #print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0HMYAyDIcQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4811a342-15df-437b-fd8a-008d8787a8d9"
      },
      "source": [
        "%%time\n",
        "\n",
        "from typing import List, Set, Dict, Tuple, Optional\n",
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import math\n",
        "from datetime import date\n",
        "from math import floor\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "\n",
        "file_prefix = './data/'\n",
        "SPAN = 3\n",
        "\n",
        "def get_cv_dataset(sales_original, month):\n",
        "  cv = sales_original[sales_original.date_block_num == month].copy()\n",
        "  cvdf = cv.groupby(['shop_id', 'item_id']).agg(\n",
        "      sold = pd.NamedAgg(column = 'item_cnt_day', aggfunc = 'sum'),\n",
        "      price = pd.NamedAgg(column = 'item_price', aggfunc = 'first')\n",
        "  )\n",
        "  cvdf.reset_index(drop = False, inplace = True)\n",
        "  cvdf.set_index('item_id', drop = True, inplace = True)\n",
        "  cvdf = cvdf.join(items, on = 'item_id')\n",
        "  cvdf.reset_index(inplace = True, drop = False)\n",
        "  \n",
        "\n",
        "  for it in range(1, SPAN + 1):\n",
        "    prev = sales_original[sales_original.date_block_num == month - it]\n",
        "    pdf = prev.groupby(['shop_id', 'item_id']).agg(\n",
        "        sold = pd.NamedAgg(column = 'item_cnt_day', aggfunc = 'sum'),\n",
        "        price = pd.NamedAgg(column = 'item_price', aggfunc = 'first')\n",
        "    )\n",
        "    cvdf = cvdf.join(pdf, on = ['shop_id', 'item_id'], rsuffix = '_' + str(it))\n",
        "    cvdf['sold_' + str(it)] = cvdf['sold_' + str(it)].fillna(0)\n",
        "    cvdf['price_' + str(it)] = cvdf['price_' + str(it)].fillna(method = 'backfill')\n",
        "    cvdf['price_' + str(it)] = cvdf['price_' + str(it)].fillna(method = 'ffill')\n",
        "\n",
        "  return cvdf\n",
        "\n",
        "### Thoughts:\n",
        "## - aggregate items per category\n",
        "##    - there are only ~80 categories, while 20k items\n",
        "##    - this will reduce the dimensionality in the final version and make\n",
        "##        the model less interpretable, albeit less accurate\n",
        "##    - what to do with the prices!!??\n",
        "##       - Around 15.5k of items have changed their price over time, ~70%\n",
        "##    - can do 2 versions and then cross validate:\n",
        "##        - with averaged and with summed volumes per item\n",
        "##    - the alternative is to use this column as a latent variable\n",
        "## - battle non-stationarity by building a model only with items that are\n",
        "##    still being sold\n",
        "## - add item price and volume history in the past months as columns\n",
        "## - add a column that asks if the item existed a year ago\n",
        "## - add a column that says how many items of such were sold last year\n",
        "##    in that month\n",
        "## - add last month's sales\n",
        "## - add a few last months' price\n",
        "## - try to backtrade the model to optimize for the parameters\n",
        "\n",
        "### Load the datasets from disk\n",
        "itemCategories=pd.read_csv(file_prefix + 'item_categories.csv')\n",
        "shops=pd.read_csv(file_prefix + 'shops.csv')\n",
        "test=pd.read_csv(file_prefix + 'test.csv')\n",
        "sales_original = pd.read_csv(file_prefix + 'sales_train.csv')\n",
        "\n",
        "items = pd.read_csv(file_prefix + 'items.csv')\n",
        "items = items.drop('item_name', axis = 1)\n",
        "items.set_index('item_id', inplace = True)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.22 s, sys: 219 ms, total: 1.44 s\n",
            "Wall time: 1.46 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHgA59oIH1O5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "67974d30-cc22-4d88-a5f9-87724a0084e0"
      },
      "source": [
        "%%time\n",
        "sales = sales_original.copy()\n",
        "\n",
        "## Separate the cross-validation set\n",
        "## TODO: implement \"rolling\" cross-validation\n",
        "## Filter here so that we are not using the future data\n",
        "sales = sales[sales.date_block_num < 32]\n",
        "\n",
        "## Aggregate prices and sales over months\n",
        "df = sales.groupby(['date_block_num', 'shop_id', 'item_id']).agg(\n",
        "    sold = pd.NamedAgg(column = 'item_cnt_day', aggfunc = 'sum'),\n",
        "    price = pd.NamedAgg(column = 'item_price', aggfunc = 'first')\n",
        ")\n",
        "df.reset_index(drop = False, inplace = True)\n",
        "\n",
        "## Append item_id category variable from the other dataset\n",
        "df.set_index('item_id', drop = True, inplace = True)\n",
        "df = df.join(items, on = 'item_id')\n",
        "df.reset_index(inplace = True, drop = False)\n",
        "\n",
        "\n",
        "### append historic data for up to SPAN months before\n",
        "aggs = df.copy()\n",
        "aggs.drop(inplace = True, columns = ['item_category_id'])\n",
        "aggs.rename(columns = {'date_block_num': 'date_block_before'}, inplace = True)\n",
        "aggs.set_index(\n",
        "    ['item_id', 'shop_id', 'date_block_before'], inplace = True, drop = True)\n",
        "for it in range(1, SPAN + 1):\n",
        "  df['date_block_before'] = df.date_block_num - it\n",
        "  ## Here is where we filter for the first month/s to always have all features\n",
        "  ## (some features are computed back in time, eg. last month's price)\n",
        "  df = df[df.date_block_before >= 0]\n",
        "  df = df.join(\n",
        "      aggs,\n",
        "      on = ['item_id', 'shop_id', 'date_block_before'],\n",
        "      rsuffix = ('_' + str(it))\n",
        "  )\n",
        "  df.drop('date_block_before', axis = 1, inplace = True)\n",
        "\n",
        "  #### Some combinations of shop-item have 0 sales in some months\n",
        "  ## those items that haven't had any sales in the given slots are assigned 0\n",
        "  ## instead of NaN\n",
        "  df['sold_' + str(it)] = df['sold_' + str(it)].fillna(0)\n",
        "  ## If the price wasn't present at the time:\n",
        "  ##   - first, fill backwards in time the last price (works with multiple prices)\n",
        "  ##   - then fill front\n",
        "  df['price_' + str(it)] = df['price_' + str(it)].fillna(method = 'backfill')\n",
        "  df['price_' + str(it)] = df['price_' + str(it)].fillna(method = 'ffill')\n",
        "\n",
        "\n",
        "## Can't use any variable that represents time, because it will\n",
        "## memorize the dataset (eg. if it knows the prices are a bit higher in\n",
        "## 2015 compared to 2013 the coeff. will be positive while the prices might fall\n",
        "## again in 2016).\n",
        "## Think about this for the final submission. IRL, using it is lying.\n",
        "df = df.drop(['date_block_num'], axis = 1)\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "\n",
        "## One-hot-encoding for item_id, shop_id, item_category_id\n",
        "\n",
        "## on collab: !pip install category_encoders\n",
        "## if local, on conda, google the conda command\n",
        "import category_encoders as ce\n",
        "\n",
        "## drop_invariant has to be True\n",
        "## it means the constant columns will be dropped\n",
        "## this will prevent the normal equations from failing - the matrix won't\n",
        "## be singular\n",
        "enc = ce.BinaryEncoder(cols=['item_id', 'shop_id', 'item_category_id'],\n",
        "                           drop_invariant = True)\n",
        "enc.fit(df.loc[:, df.columns != 'sold'], df.sold)\n",
        "X = enc.transform(df.loc[:, df.columns != 'sold'])\n",
        "Y = df.sold"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.24 s, sys: 974 ms, total: 9.21 s\n",
            "Wall time: 9.27 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTdWPJroH3Y3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "f9f5f0f2-64fa-4631-dddc-4ec4b6fb2e35"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.matshow(df.loc[:, df.columns.isin(['price', 'price_1', 'sold_1', 'sold_2', 'sold_3', 'price_2', 'sold'])].corr())\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWb9HugPSiIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98519a99-1d55-4180-83ff-5bf6935f7337"
      },
      "source": [
        "%%time\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "X = sm.add_constant(X) ## add offset\n",
        "\n",
        "model = sm.OLS(Y, X).fit()\n",
        "predictions = model.predict(X) \n",
        "\n",
        "print_model = model.summary()\n",
        "print(print_model)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                   sold   R-squared:                       0.526\n",
            "Model:                            OLS   Adj. R-squared:                  0.526\n",
            "Method:                 Least Squares   F-statistic:                 4.313e+04\n",
            "Date:                Wed, 22 Apr 2020   Prob (F-statistic):               0.00\n",
            "Time:                        00:29:37   Log-Likelihood:            -4.3505e+06\n",
            "No. Observations:             1360779   AIC:                         8.701e+06\n",
            "Df Residuals:                 1360743   BIC:                         8.701e+06\n",
            "Df Model:                          35                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "======================================================================================\n",
            "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------\n",
            "const                  0.9131      0.028     32.616      0.000       0.858       0.968\n",
            "item_id_1              0.4537      0.018     24.967      0.000       0.418       0.489\n",
            "item_id_2              0.2360      0.012     18.931      0.000       0.212       0.260\n",
            "item_id_3              0.0045      0.012      0.375      0.707      -0.019       0.028\n",
            "item_id_4              0.0844      0.011      7.870      0.000       0.063       0.105\n",
            "item_id_5             -0.0093      0.010     -0.884      0.376      -0.030       0.011\n",
            "item_id_6              0.0875      0.010      8.483      0.000       0.067       0.108\n",
            "item_id_7              0.0053      0.010      0.508      0.611      -0.015       0.026\n",
            "item_id_8              0.0077      0.010      0.750      0.453      -0.012       0.028\n",
            "item_id_9              0.0547      0.010      5.372      0.000       0.035       0.075\n",
            "item_id_10             0.0856      0.010      8.398      0.000       0.066       0.106\n",
            "item_id_11            -0.0620      0.010     -6.100      0.000      -0.082      -0.042\n",
            "item_id_12            -0.0794      0.010     -7.806      0.000      -0.099      -0.059\n",
            "item_id_13            -0.0910      0.010     -8.955      0.000      -0.111      -0.071\n",
            "item_id_14             0.0451      0.010      4.437      0.000       0.025       0.065\n",
            "item_id_15            -0.0626      0.010     -6.162      0.000      -0.083      -0.043\n",
            "shop_id_1              0.0065      0.012      0.525      0.599      -0.018       0.031\n",
            "shop_id_2              0.0533      0.012      4.315      0.000       0.029       0.077\n",
            "shop_id_3             -0.0071      0.010     -0.679      0.497      -0.028       0.013\n",
            "shop_id_4             -0.0602      0.011     -5.731      0.000      -0.081      -0.040\n",
            "shop_id_5             -0.0415      0.010     -4.039      0.000      -0.062      -0.021\n",
            "shop_id_6              0.0318      0.010      3.082      0.002       0.012       0.052\n",
            "price               5.878e-05   4.64e-06     12.678      0.000    4.97e-05    6.79e-05\n",
            "item_category_id_1     0.6840      0.033     20.455      0.000       0.618       0.750\n",
            "item_category_id_2     0.2569      0.016     16.420      0.000       0.226       0.288\n",
            "item_category_id_3     0.0239      0.013      1.841      0.066      -0.002       0.049\n",
            "item_category_id_4     0.0563      0.012      4.638      0.000       0.033       0.080\n",
            "item_category_id_5     0.0768      0.014      5.617      0.000       0.050       0.104\n",
            "item_category_id_6    -0.1484      0.012    -12.426      0.000      -0.172      -0.125\n",
            "item_category_id_7     0.0384      0.013      2.996      0.003       0.013       0.064\n",
            "sold_1                 0.4890      0.001    568.709      0.000       0.487       0.491\n",
            "price_1            -5.405e-05   4.79e-06    -11.276      0.000   -6.34e-05   -4.47e-05\n",
            "sold_2                 0.1444      0.001    144.124      0.000       0.142       0.146\n",
            "price_2            -6.509e-05   4.93e-06    -13.196      0.000   -7.48e-05   -5.54e-05\n",
            "sold_3                 0.1957      0.001    211.309      0.000       0.194       0.198\n",
            "price_3             7.225e-08   4.73e-06      0.015      0.988   -9.19e-06    9.34e-06\n",
            "==============================================================================\n",
            "Omnibus:                  4162699.768   Durbin-Watson:                   1.679\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):    2427501896084.882\n",
            "Skew:                          45.487   Prob(JB):                         0.00\n",
            "Kurtosis:                    6545.589   Cond. No.                     2.02e+04\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.02e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "CPU times: user 9.25 s, sys: 1.63 s, total: 10.9 s\n",
            "Wall time: 7.19 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTKaZLEvSlDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cross validation for the last month\n",
        "cvdf = get_cv_dataset(sales_original, 32)\n",
        "\n",
        "X_cv = enc.transform(cvdf.loc[:, cvdf.columns != 'sold'])\n",
        "X_cv = sm.add_constant(X_cv) ## add offset\n",
        "Y_cv = cvdf.sold\n",
        "\n",
        "predictions = model.predict(X_cv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9V7Xo5JSpo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57667092-3c8b-42de-f24a-1b33298d7995"
      },
      "source": [
        "from statsmodels.tools.eval_measures import mse as mse\n",
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17.156509971134057, 73.88989502150442)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2POnvLxSuZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "e2d31f87-6152-4ab4-c2b8-c011b3ad0ab4"
      },
      "source": [
        "### RANDOM CODE BITS                                        \n",
        "\n",
        "### REALLY IMPORTANT - the most general version of \n",
        "##              groupby and aggregate concept                                  \n",
        "In [3]: animals.groupby(\"item_id\").agg(\n",
        "   ...:     avg_price=pd.NamedAgg(column='height', aggfunc='min'),\n",
        "   ...:     price=pd.NamedAgg(column='height', aggfunc='max'),\n",
        "   ...:     average_weight=pd.NamedAgg(column='weight', aggfunc=np.mean),\n",
        "   ...: )\n",
        "\n",
        "   ## unused for now\n",
        "## REDO THIS!\n",
        "## don't delete, this unstack idea is top shit and will be needed for sure\n",
        "def agg_months_as_columns(sales):\n",
        "  df['month'] = df.time.dt.month\n",
        "  df = pd.DataFrame(sales.groupby(['month', 'shop_id', 'item_id', \\\n",
        "                                   'item_price'])['item_cnt_day'].sum())\n",
        "  df = df.unstack(level = 0)\n",
        "  df = df.fillna(0)\n",
        "  df.columns = df.columns.get_level_values(1)\n",
        "  df.reset_index(drop = False, inplace = True)\n",
        "  df.columns = ['shop_id', 'item_price','Jan', 'Feb',\\\n",
        "                'Mar',  'Apr', 'May',  'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "  return df\n",
        "\n",
        "\n",
        "def get_sales_for_month(sales, month):\n",
        "  df = pd.DataFrame(sales[sales.time.dt.month == month].groupby(['shop_id', 'item_id', 'item_price'])['item_cnt_day'].sum())\n",
        "  df = df.fillna(0)\n",
        "  df.columns = ['usual_sales_at_target_time']\n",
        "  df.reset_index(drop = False, inplace = True)\n",
        "  return df\n",
        "\n",
        "\n",
        "### TODO: think about this forward selection stuff\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "def forward_selected(data, response):\n",
        "    \"\"\"Linear model designed by forward selection.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : pandas DataFrame with all possible predictors and response\n",
        "\n",
        "    response: string, name of response column in data\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    model: an \"optimal\" fitted statsmodels linear model\n",
        "           with an intercept\n",
        "           selected by forward selection\n",
        "           evaluated by adjusted R-squared\n",
        "    \"\"\"\n",
        "    remaining = set(data.columns)\n",
        "    remaining.remove(response)\n",
        "    selected = []\n",
        "    current_score, best_new_score = 0.0, 0.0\n",
        "    while remaining and current_score == best_new_score:\n",
        "        scores_with_candidates = []\n",
        "        for candidate in remaining:\n",
        "            formula = \"{} ~ {} + 1\".format(response,\n",
        "                                           ' + '.join(selected + [candidate]))\n",
        "            score = smf.ols(formula, data).fit().rsquared_adj\n",
        "            scores_with_candidates.append((score, candidate))\n",
        "        scores_with_candidates.sort()\n",
        "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
        "        if current_score < best_new_score:\n",
        "            remaining.remove(best_candidate)\n",
        "            selected.append(best_candidate)\n",
        "            current_score = best_new_score\n",
        "    formula = \"{} ~ {} + 1\".format(response,\n",
        "                                   ' + '.join(selected))\n",
        "    model = smf.ols(formula, data).fit()\n",
        "    return model\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-50a14c70b7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m animals.groupby(\"item_id\").agg(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mavg_price\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedAgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'height'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedAgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'height'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maverage_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedAgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'animals' is not defined"
          ]
        }
      ]
    }
  ]
}