{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/josipbencic/kaggle/blob/master/predict_future_sales_josip.ipynb",
      "authorship_tag": "ABX9TyO8VdMH8qT8sZEH1NvlMf6x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josipbencic/kaggle/blob/master/predict_future_sales_josip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo2Ssr0VHt2P",
        "colab_type": "text"
      },
      "source": [
        "### 0 Technical boilerplate to make the notebook work\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWaWo5-YHuR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80bafa4c-dc0c-46c8-e26c-e84a38e9faaf"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "PROJECT_PATH = \"/content/drive/My Drive/kaggle_tmp\"\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "\n",
        "GIT_TOKEN = \"13b32b3481c45a9a7bdd7f223644aa47b1156c42\"\n",
        "GIT_USERNAME = \"josipbencic\"\n",
        "GIT_REPOSITORY = \"kaggle\"\n",
        "\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "\n",
        "!git clone \"{GIT_PATH}\" ./temp      # clone github repository to temp folder\n",
        "!cp -R ./temp/* \"{PROJECT_PATH}\"    # move all files/folders in temp folder to folder defined in project path\n",
        "!rm -rf ./temp                      # remove all the files/folders in temp folder\n",
        "#!rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./   # use remote sync to copy from google drive to local runtime google colab\n",
        "                                                     # but exclude data folder                                          \n",
        "!rsync -aP \"{PROJECT_PATH}\"/* ./\n",
        "\n",
        "!pip install category_encoders\n",
        "\n",
        "## Inspect collab machine\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "!pip install pycuda\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Cloning into './temp'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 38 (delta 11), reused 22 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (38/38), done.\n",
            "sending incremental file list\n",
            "README.md\n",
            "            605 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=11/12)\n",
            "environment.yml\n",
            "            211 100%   51.51kB/s    0:00:00 (xfr#2, to-chk=10/12)\n",
            "predict_future_sales_josip.ipynb\n",
            "         28,225 100%    5.38MB/s    0:00:00 (xfr#3, to-chk=9/12)\n",
            "predict_future_sales_kristijan.ipynb\n",
            "            971 100%  189.65kB/s    0:00:00 (xfr#4, to-chk=8/12)\n",
            "template.ipynb\n",
            "         11,516 100%    1.83MB/s    0:00:00 (xfr#5, to-chk=7/12)\n",
            "data/\n",
            "data/item_categories.csv\n",
            "          3,573 100%  498.47kB/s    0:00:00 (xfr#6, to-chk=5/12)\n",
            "data/items.csv\n",
            "      1,568,417 100%   99.72MB/s    0:00:00 (xfr#7, to-chk=4/12)\n",
            "data/sales_train.csv\n",
            "     94,603,866 100%  188.75MB/s    0:00:00 (xfr#8, to-chk=3/12)\n",
            "data/sample_submission.csv\n",
            "      2,245,108 100%    4.28MB/s    0:00:00 (xfr#9, to-chk=2/12)\n",
            "data/shops.csv\n",
            "          2,977 100%    5.80kB/s    0:00:00 (xfr#10, to-chk=1/12)\n",
            "data/test.csv\n",
            "      3,182,735 100%    5.88MB/s    0:00:00 (xfr#11, to-chk=0/12)\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.3)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/3f/5658c38579b41866ba21ee1b5020b8225cec86fe717e4b1c5c972de0a33c/pycuda-2019.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 2.8MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/c7/88a4f8b6f0f78d0115ec3320861a0cc1f6daa3b67e97c3c2842c33f9c089/pytools-2020.1.tar.gz (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/78/f6ade1e18aebda570eed33b7c534378d9659351cadce2fcbc7b31be5f615/Mako-1.1.2-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVWwMdXIFOiu",
        "colab_type": "text"
      },
      "source": [
        "### 1 Thoughts, ideas, conclusions\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk16iBxWIF8d",
        "colab_type": "text"
      },
      "source": [
        "Ideas\n",
        "\n",
        "- aggregate items per category instead of per item_id\n",
        "   - there are only ~80 categories, while 20k items\n",
        "   - this will reduce the dimensionality in the final version and make\n",
        "       the model more interpretable, albeit less accurate\n",
        "   - in that case, what to do with the prices!!??\n",
        "      - Around 15.5k of items have changed their price over time, ~70%\n",
        "   - can do 2 versions and then cross validate:\n",
        "       - with averaged and with summed volumes per item\n",
        "   - the alternative is to use this column as a latent variable\n",
        "- battle non-stationarity by building a model only with items that are\n",
        "   still being sold\n",
        "- add item price and volume history in the past months as columns\n",
        "- add a column that asks if the item existed a year ago\n",
        "- add a column that says how many items of such were sold last year\n",
        "   in that month\n",
        "- add last month's sales\n",
        "- add a few last months' price\n",
        "- try to backtrade the model to optimize for the parameters\n",
        "\n",
        "Conclusions\n",
        "- it's better to model with logarithm of prices rather than with the price itself\n",
        "  - actually, prices are fucking up everything\n",
        "  - except the current price, that's useful\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVhPGfSRH3ea",
        "colab_type": "text"
      },
      "source": [
        "### 2 Includes and data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0HMYAyDIcQo",
        "colab_type": "code",
        "outputId": "410b949e-5802-4828-ef03-125dcd3729f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "%%time\n",
        "from typing import List, Set, Dict, Tuple, Optional\n",
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import math\n",
        "from datetime import date\n",
        "from math import floor\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "\n",
        "import category_encoders as ce\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools.eval_measures import mse as mse\n",
        "from statsmodels.multivariate.pca import PCA\n",
        "\n",
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import numpy as np\n",
        "import skcuda.linalg as linalg\n",
        "from skcuda.linalg import PCA as cuPCA\n",
        "\n",
        "file_prefix = './data/'\n",
        "\n",
        "### Load the datasets from disk\n",
        "itemCategories=pd.read_csv(file_prefix + 'item_categories.csv')\n",
        "shops=pd.read_csv(file_prefix + 'shops.csv')\n",
        "test=pd.read_csv(file_prefix + 'test.csv')\n",
        "sales_original = pd.read_csv(file_prefix + 'sales_train.csv')\n",
        "\n",
        "items = pd.read_csv(file_prefix + 'items.csv')\n",
        "items = items.drop('item_name', axis = 1)\n",
        "items.set_index('item_id', inplace = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5cacc2558c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from typing import List, Set, Dict, Tuple, Optional\\nimport argparse\\nimport sys\\nimport os\\nimport csv\\nimport time\\nimport math\\nfrom datetime import date\\nfrom math import floor\\n\\nimport numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport matplotlib.dates as mdates\\nfrom pandas.plotting import register_matplotlib_converters\\nregister_matplotlib_converters()\\n\\nimport category_encoders as ce\\nimport statsmodels.api as sm\\nfrom statsmodels.tools.eval_measures import mse as mse\\nfrom statsmodels.multivariate.pca import PCA\\n\\n\\nimport pycuda.autoinit\\nimport pycuda.gpuarray as gpuarray\\nimport numpy as np\\nimport skcuda.linalg as linalg\\nfrom skcuda.linalg import PCA as cuPCA\\n\\nfile_prefix = './data/'\\n\\n### Load the datasets from disk\\nitemCategories=pd.read_csv(file_prefix + 'item_categories.csv')\\nshops=pd.read_csv(file_prefix + 'shops.csv')\\ntest=pd.read_csv(file_prefix + 'test.csv')\\nsales_original = pd.read_csv(file_prefix + 'sales_train.csv')\\n\\nitems = pd.read_csv(file_prefix + 'items.csv')\\nitems = items.drop('item_name', axis = 1)\\nitems.set_index('item_id', inplace = True)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4kwx0ECH_Cg",
        "colab_type": "text"
      },
      "source": [
        "### 3 Data Cleaning, Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHgA59oIH1O5",
        "colab_type": "code",
        "outputId": "5e12f48f-c773-4e41-d56d-8c3d66a199a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "SPAN = 5\n",
        "sales = sales_original.copy()\n",
        "\n",
        "## Separate the cross-validation set\n",
        "## TODO: implement \"rolling\" cross-validation\n",
        "## Filter here so that we are not using the future data\n",
        "sales = sales[sales.date_block_num < 32]\n",
        "\n",
        "## Aggregate prices and sales over months\n",
        "df = sales.groupby(['date_block_num', 'shop_id', 'item_id']).agg(\n",
        "    sold = pd.NamedAgg(column = 'item_cnt_day', aggfunc = 'sum'),\n",
        "    price = pd.NamedAgg(column = 'item_price', aggfunc = 'first')\n",
        ")\n",
        "df.reset_index(drop = False, inplace = True)\n",
        "\n",
        "## Append item_id category variable from the other dataset\n",
        "df.set_index('item_id', drop = True, inplace = True)\n",
        "df = df.join(items, on = 'item_id')\n",
        "df.reset_index(inplace = True, drop = False)\n",
        "\n",
        "\n",
        "### append historic data for up to SPAN months before\n",
        "aggs = df.copy()\n",
        "aggs.drop(inplace = True, columns = ['item_category_id'])\n",
        "aggs.rename(columns = {'date_block_num': 'date_block_before'}, inplace = True)\n",
        "aggs.set_index(\n",
        "    ['item_id', 'shop_id', 'date_block_before'], inplace = True, drop = True)\n",
        "for it in range(1, SPAN + 1):\n",
        "  df['date_block_before'] = df.date_block_num - it\n",
        "  ## Here is where we filter for the first month/s to always have all features\n",
        "  ## (some features are computed back in time, eg. last month's price)\n",
        "  df = df[df.date_block_before >= 0]\n",
        "  df = df.join(\n",
        "      aggs,\n",
        "      on = ['item_id', 'shop_id', 'date_block_before'],\n",
        "      rsuffix = ('_' + str(it))\n",
        "  )\n",
        "  df.drop('date_block_before', axis = 1, inplace = True)\n",
        "\n",
        "  #### Some combinations of shop-item have 0 sales in some months\n",
        "  ## those items that haven't had any sales in the given slots are assigned 0\n",
        "  ## instead of NaN\n",
        "  df['sold_' + str(it)] = df['sold_' + str(it)].fillna(0)\n",
        "  ## If the price wasn't present at the time:\n",
        "  ##   - first, fill backwards in time the last price (works with multiple prices)\n",
        "  ##   - then fill front\n",
        "  df['price_' + str(it)] = df['price_' + str(it)].fillna(method = 'backfill')\n",
        "  df['price_' + str(it)] = df['price_' + str(it)].fillna(method = 'ffill')\n",
        "  df['price_' + str(it) + '_log'] = np.log(df['price_' + str(it)].values)\n",
        "  df = df.drop('price_' + str(it), axis = 1)\n",
        "df['price_log'] = np.log(df['price'].values)\n",
        "#df = df.drop('price', axis = 1)\n",
        "\n",
        "\n",
        "## Can't use any variable that represents time, because it will\n",
        "## memorize the dataset (eg. if it knows the prices are a bit higher in\n",
        "## 2015 compared to 2013 the coeff. will be positive while the prices might fall\n",
        "## again in 2016).\n",
        "## Think about this for the final submission. IRL, using it is lying.\n",
        "df = df.drop(['date_block_num'], axis = 1)\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "\n",
        "\n",
        "## One-hot-encoding for item_id, shop_id, item_category_id\n",
        "## drop_invariant has to be True\n",
        "##    it means the constant columns will be dropped\n",
        "##    this will prevent the normal equations from failing - the matrix won't\n",
        "##    be singular\n",
        "enc = ce.BinaryEncoder(cols=['item_id', 'shop_id', 'item_category_id'],\n",
        "                           drop_invariant = True)\n",
        "enc.fit(df.loc[:, df.columns != 'sold'], df.sold)\n",
        "X = enc.transform(df.loc[:, df.columns != 'sold'])\n",
        "Y = df.sold"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.6 s, sys: 817 ms, total: 12.5 s\n",
            "Wall time: 12.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63mVZ9__UvJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### PCA\n",
        "pca = PCA(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onsk9hqOU3C4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "58362336-f22f-4c7b-f75a-f357562764e0"
      },
      "source": [
        "pca.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3af03aafbf1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pca' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWb9HugPSiIf",
        "colab_type": "code",
        "outputId": "b712400d-49e0-422e-e559-bb330c57f1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "## Model building\n",
        "\n",
        "X = sm.add_constant(X) ## add offset\n",
        "\n",
        "model = sm.OLS(Y, X).fit()\n",
        "predictions = model.predict(X) \n",
        "\n",
        "print_model = model.summary()\n",
        "print(print_model)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                   sold   R-squared:                       0.545\n",
            "Model:                            OLS   Adj. R-squared:                  0.545\n",
            "Method:                 Least Squares   F-statistic:                 3.754e+04\n",
            "Date:                Wed, 22 Apr 2020   Prob (F-statistic):               0.00\n",
            "Time:                        19:02:19   Log-Likelihood:            -4.0177e+06\n",
            "No. Observations:             1252845   AIC:                         8.036e+06\n",
            "Df Residuals:                 1252804   BIC:                         8.036e+06\n",
            "Df Model:                          40                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "======================================================================================\n",
            "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------\n",
            "const                  3.0625      0.062     49.256      0.000       2.941       3.184\n",
            "item_id_1              0.6899      0.020     33.959      0.000       0.650       0.730\n",
            "item_id_2              0.3574      0.013     27.468      0.000       0.332       0.383\n",
            "item_id_3             -0.0234      0.013     -1.823      0.068      -0.049       0.002\n",
            "item_id_4              0.0666      0.011      5.808      0.000       0.044       0.089\n",
            "item_id_5             -0.0229      0.011     -2.061      0.039      -0.045      -0.001\n",
            "item_id_6             -0.0443      0.011     -4.044      0.000      -0.066      -0.023\n",
            "item_id_7              0.0075      0.011      0.688      0.492      -0.014       0.029\n",
            "item_id_8              0.0236      0.011      2.183      0.029       0.002       0.045\n",
            "item_id_9              0.0221      0.011      2.052      0.040       0.001       0.043\n",
            "item_id_10            -0.1047      0.011     -9.752      0.000      -0.126      -0.084\n",
            "item_id_11            -0.0634      0.011     -5.917      0.000      -0.084      -0.042\n",
            "item_id_12            -0.0329      0.011     -3.075      0.002      -0.054      -0.012\n",
            "item_id_13             0.0314      0.011      2.931      0.003       0.010       0.052\n",
            "item_id_14            -0.0448      0.011     -4.189      0.000      -0.066      -0.024\n",
            "item_id_15            -0.0185      0.011     -1.729      0.084      -0.039       0.002\n",
            "shop_id_1             -0.0363      0.013     -2.713      0.007      -0.063      -0.010\n",
            "shop_id_2              0.0078      0.013      0.603      0.547      -0.018       0.033\n",
            "shop_id_3              0.0129      0.011      1.179      0.238      -0.009       0.034\n",
            "shop_id_4             -0.0157      0.011     -1.421      0.155      -0.037       0.006\n",
            "shop_id_5             -0.0054      0.011     -0.499      0.618      -0.027       0.016\n",
            "shop_id_6             -0.0202      0.011     -1.823      0.068      -0.042       0.002\n",
            "price               7.944e-05   4.56e-06     17.420      0.000    7.05e-05    8.84e-05\n",
            "item_category_id_1     0.7990      0.035     23.039      0.000       0.731       0.867\n",
            "item_category_id_2     0.2059      0.017     12.316      0.000       0.173       0.239\n",
            "item_category_id_3     0.0409      0.016      2.494      0.013       0.009       0.073\n",
            "item_category_id_4     0.2039      0.015     13.882      0.000       0.175       0.233\n",
            "item_category_id_5     0.0541      0.012      4.584      0.000       0.031       0.077\n",
            "item_category_id_6     0.0360      0.012      2.916      0.004       0.012       0.060\n",
            "item_category_id_7    -0.0053      0.013     -0.416      0.678      -0.030       0.020\n",
            "sold_1                 0.4664      0.001    515.333      0.000       0.465       0.468\n",
            "price_1_log           -0.1783      0.007    -23.846      0.000      -0.193      -0.164\n",
            "sold_2                 0.1207      0.001    114.576      0.000       0.119       0.123\n",
            "price_2_log           -0.1685      0.008    -22.000      0.000      -0.184      -0.154\n",
            "sold_3                 0.1298      0.001    119.954      0.000       0.128       0.132\n",
            "price_3_log           -0.0604      0.008     -7.819      0.000      -0.076      -0.045\n",
            "sold_4                 0.0494      0.001     42.909      0.000       0.047       0.052\n",
            "price_4_log           -0.0027      0.008     -0.353      0.724      -0.018       0.012\n",
            "sold_5                 0.1087      0.001    100.711      0.000       0.107       0.111\n",
            "price_5_log            0.0432      0.007      5.916      0.000       0.029       0.057\n",
            "price_log             -0.0142      0.009     -1.632      0.103      -0.031       0.003\n",
            "==============================================================================\n",
            "Omnibus:                  3864560.321   Durbin-Watson:                   1.671\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):    2327513318376.238\n",
            "Skew:                          46.586   Prob(JB):                         0.00\n",
            "Kurtosis:                    6679.683   Cond. No.                     2.10e+04\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.1e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "CPU times: user 10.6 s, sys: 694 ms, total: 11.3 s\n",
            "Wall time: 6.86 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkvUpnC3HOZG",
        "colab_type": "text"
      },
      "source": [
        "### 4 Model Checking - Cross Validation and other\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTKaZLEvSlDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cv_dataset(sales_original, month, span):\n",
        "  cv = sales_original[sales_original.date_block_num == month].copy()\n",
        "  cvdf = cv.groupby(['shop_id', 'item_id']).agg(\n",
        "      sold = pd.NamedAgg(column = 'item_cnt_day', aggfunc = 'sum'),\n",
        "      price = pd.NamedAgg(column = 'item_price', aggfunc = 'first')\n",
        "  )\n",
        "  cvdf.reset_index(drop = False, inplace = True)\n",
        "  cvdf.set_index('item_id', drop = True, inplace = True)\n",
        "  cvdf = cvdf.join(items, on = 'item_id')\n",
        "  cvdf.reset_index(inplace = True, drop = False)\n",
        "  \n",
        "  for it in range(1, span + 1):\n",
        "    prev = sales_original[sales_original.date_block_num == month - it]\n",
        "    pdf = prev.groupby(['shop_id', 'item_id']).agg(\n",
        "        sold = pd.NamedAgg(column = 'item_cnt_day', aggfunc = 'sum'),\n",
        "        price = pd.NamedAgg(column = 'item_price', aggfunc = 'first')\n",
        "    )\n",
        "    cvdf = cvdf.join(pdf, on = ['shop_id', 'item_id'], rsuffix = '_' + str(it))\n",
        "    cvdf['sold_' + str(it)] = cvdf['sold_' + str(it)].fillna(0)\n",
        "    cvdf['price_' + str(it)] = cvdf['price_' + str(it)].fillna(method = 'backfill')\n",
        "    cvdf['price_' + str(it)] = cvdf['price_' + str(it)].fillna(method = 'ffill')\n",
        "    cvdf['price_' + str(it) + '_log' ] = np.log(cvdf['price_' + str(it)].values)\n",
        "    cvdf = cvdf.drop('price_' + str(it), axis = 1)\n",
        "  cvdf['price_log'] = np.log(cvdf['price'].values)\n",
        "  #cvdf = cvdf.drop('price', axis = 1)\n",
        "  return cvdf\n",
        "\n",
        "cvdf = get_cv_dataset(sales_original, 32, SPAN)\n",
        "\n",
        "X_cv = enc.transform(cvdf.loc[:, cvdf.columns != 'sold'])\n",
        "X_cv = sm.add_constant(X_cv) ## add offset\n",
        "Y_cv = cvdf.sold\n",
        "\n",
        "predictions = model.predict(X_cv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_L6gHezQcXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf89598d-351d-44ef-81cb-c4679865d223"
      },
      "source": [
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17.165870950393856, 78.54915343910456)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cErWmbjNDfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d87a6d9-cf9d-4834-bcd2-5b3ce605a9ac"
      },
      "source": [
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17.166284993830292, 78.54915343910456)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9V7Xo5JSpo1",
        "colab_type": "code",
        "outputId": "57667092-3c8b-42de-f24a-1b33298d7995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17.156509971134057, 73.88989502150442)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZazxAXqES8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.matshow(df.loc[:, df.columns.isin(['price_log', 'price_1_log', 'sold_1', 'sold_2', 'sold_3', 'price_2_log', 'sold'])].corr())\n",
        "#plt.show()\n",
        "\n",
        "sns.pairplot(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwh61ecDHZRQ",
        "colab_type": "text"
      },
      "source": [
        "### Extra: Random code bits\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2POnvLxSuZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## don't delete, this unstack idea is top shit and will be needed for sure\n",
        "def agg_months_as_columns(sales):\n",
        "  df['month'] = df.time.dt.month\n",
        "  df = pd.DataFrame(sales.groupby(['month', 'shop_id', 'item_id', \\\n",
        "                                   'item_price'])['item_cnt_day'].sum())\n",
        "  df = df.unstack(level = 0)\n",
        "  df = df.fillna(0)\n",
        "  df.columns = df.columns.get_level_values(1)\n",
        "  df.reset_index(drop = False, inplace = True)\n",
        "  df.columns = ['shop_id', 'item_price','Jan', 'Feb',\\\n",
        "                'Mar',  'Apr', 'May',  'Jun', 'Jul',  \\\n",
        "                'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "  return df\n",
        "\n",
        "### Forward selection with statsmodels\n",
        "def forward_selected(data, response):\n",
        "    \"\"\"Linear model designed by forward selection.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : pandas DataFrame with all possible predictors and response\n",
        "\n",
        "    response: string, name of response column in data\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    model: an \"optimal\" fitted statsmodels linear model\n",
        "           with an intercept\n",
        "           selected by forward selection\n",
        "           evaluated by adjusted R-squared\n",
        "    \"\"\"\n",
        "    remaining = set(data.columns)\n",
        "    remaining.remove(response)\n",
        "    selected = []\n",
        "    current_score, best_new_score = 0.0, 0.0\n",
        "    while remaining and current_score == best_new_score:\n",
        "        scores_with_candidates = []\n",
        "        for candidate in remaining:\n",
        "            formula = \"{} ~ {} + 1\".format(response,\n",
        "                                           ' + '.join(selected + [candidate]))\n",
        "            score = smf.ols(formula, data).fit().rsquared_adj\n",
        "            scores_with_candidates.append((score, candidate))\n",
        "        scores_with_candidates.sort()\n",
        "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
        "        if current_score < best_new_score:\n",
        "            remaining.remove(best_candidate)\n",
        "            selected.append(best_candidate)\n",
        "            current_score = best_new_score\n",
        "    formula = \"{} ~ {} + 1\".format(response,\n",
        "                                   ' + '.join(selected))\n",
        "    model = smf.ols(formula, data).fit()\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}