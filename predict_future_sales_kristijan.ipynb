{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josipbencic/kaggle/blob/master/predict_future_sales_kristijan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qha1WQzF1Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "PROJECT_PATH = \"/content/drive/My Drive/kaggle_tmp\"\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "\n",
        "GIT_TOKEN = \"097309d50a5b76d973c1011b2194720f119234c8\"\n",
        "GIT_USERNAME = \"josipbencic\"\n",
        "GIT_REPOSITORY = \"kaggle\"\n",
        "\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "\n",
        "!git clone \"{GIT_PATH}\" ./temp      # clone github repository to temp folder\n",
        "!cp -R ./temp/* \"{PROJECT_PATH}\"    # move all files/folders in temp folder to folder defined in project path\n",
        "!rm -rf ./temp                      # remove all the files/folders in temp folder\n",
        "#!rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./   # use remote sync to copy from google drive to local runtime google colab\n",
        "                                                     # but exclude data folder                                          \n",
        "!rsync -aP \"{PROJECT_PATH}\"/* ./  \n",
        "\n",
        "!pip install category_encoders\n",
        "!pip install pycuda\n",
        "!pip install scikit-cuda\n",
        "!pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfSNTbsubkw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Inspect collab machine\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYOxgaFibk8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from typing import List, Set, Dict, Tuple, Optional\n",
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import math\n",
        "from datetime import date\n",
        "from math import floor\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "\n",
        "import category_encoders as ce\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools.eval_measures import mse as mse\n",
        "from statsmodels.multivariate.pca import PCA\n",
        "\n",
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import numpy as np\n",
        "import skcuda.linalg as linalg\n",
        "from skcuda.linalg import PCA as cuPCA\n",
        "\n",
        "file_prefix = './data/'\n",
        "\n",
        "### Load the datasets from disk\n",
        "itemCategories=pd.read_csv(file_prefix + 'item_categories.csv')\n",
        "shops=pd.read_csv(file_prefix + 'shops.csv')\n",
        "test=pd.read_csv(file_prefix + 'test.csv')\n",
        "sales_original = pd.read_csv(file_prefix + 'sales_train.csv')\n",
        "\n",
        "items = pd.read_csv(file_prefix + 'items.csv')\n",
        "items = items.drop('item_name', axis = 1)\n",
        "items.set_index('item_id', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2yY9jmCeYRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_variable(shape, w=0.1):\n",
        "  initial = tf.truncated_normal(shape, stddev=w)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape, w=0.1):\n",
        "  initial = tf.constant(w, shape=shape)\n",
        "  return tf.Variable(initial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALcPDTfUeZuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indim=trainx.shape[1]\n",
        "l1=10\n",
        "outp=1\n",
        "W1=weight_variable([indim,l1])\n",
        "W2=weight_variable([l1,outp])\n",
        "\n",
        "b1=bias_variable([l1])\n",
        "b2=bias_variable([outp])\n",
        "\n",
        "x=tf.placeholder(tf.float32,[None,indim],name=\"input\")\n",
        "y=tf.placeholder(tf.float32,[None,outp],name=\"output\")\n",
        "\n",
        "trainep=1000\n",
        "\n",
        "model1=tf.sigmoid(tf.matmul(x,W1)+b1)\n",
        "model2=tf.sigmoid(tf.matmul(model1,W2)+b2)\n",
        "\n",
        "loss=tf.reduce_sum(tf.square(model2-y))\n",
        "\n",
        "train=tf.train.GradientDescentOptimizer(1).minimize(loss)\n",
        "\n",
        "\n",
        "init=tf.global_variables_initializer()\n",
        "sess=tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for i in range (trainep):       #ustekas input i output i pustis da trenira\n",
        "  sess.run(train,{x:??,y:??})\n",
        "\n",
        "sess.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}