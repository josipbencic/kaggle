{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/josipbencic/kaggle/blob/master/predict_future_sales_josip.ipynb",
      "authorship_tag": "ABX9TyNXoVvi1+27v9l6LClzHhWh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josipbencic/kaggle/blob/master/predict_future_sales_josip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo2Ssr0VHt2P",
        "colab_type": "text"
      },
      "source": [
        "### 0 Technical boilerplate to make the notebook work\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWaWo5-YHuR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "PROJECT_PATH = \"/content/drive/My Drive/kaggle_tmp\"\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "\n",
        "GIT_TOKEN = \"13b32b3481c45a9a7bdd7f223644aa47b1156c42\"\n",
        "GIT_USERNAME = \"josipbencic\"\n",
        "GIT_REPOSITORY = \"kaggle\"\n",
        "\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "\n",
        "!git clone \"{GIT_PATH}\" ./temp      # clone github repository to temp folder\n",
        "!cp -R ./temp/* \"{PROJECT_PATH}\"    # move all files/folders in temp folder to folder defined in project path\n",
        "!rm -rf ./temp                      # remove all the files/folders in temp folder\n",
        "#!rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./   # use remote sync to copy from google drive to local runtime google colab\n",
        "                                                     # but exclude data folder                                          \n",
        "!rsync -aP \"{PROJECT_PATH}\"/* ./\n",
        "\n",
        "!pip install category_encoders\n",
        "!pip install pycuda\n",
        "!pip install scikit-cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQxk9KGFlSBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Inspect collab machine\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVWwMdXIFOiu",
        "colab_type": "text"
      },
      "source": [
        "### 1 Thoughts, ideas, conclusions\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk16iBxWIF8d",
        "colab_type": "text"
      },
      "source": [
        "Ideas\n",
        "\n",
        "- aggregate items per category instead of per item_id\n",
        "   - there are only ~80 categories, while 20k items\n",
        "   - this will reduce the dimensionality in the final version and make\n",
        "       the model more interpretable, albeit less accurate\n",
        "   - in that case, what to do with the prices!!??\n",
        "      - Around 15.5k of items have changed their price over time, ~70%\n",
        "   - can do 2 versions and then cross validate:\n",
        "       - with averaged and with summed volumes per item\n",
        "   - the alternative is to use this column as a latent variable\n",
        "- battle non-stationarity by building a model only with items that are\n",
        "   still being sold\n",
        "- add item price and volume history in the past months as columns\n",
        "- add a column that asks if the item existed a year ago\n",
        "- add a column that says how many items of such were sold last year\n",
        "   in that month\n",
        "- add last month's sales\n",
        "- add a few last months' price\n",
        "- try to backtrade the model to optimize for the parameters\n",
        "\n",
        "Conclusions\n",
        "- it's better to model with logarithm of prices rather than with the price itself\n",
        "  - actually, prices are fucking up everything\n",
        "  - except the current price, that's useful\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SF3_fHcUpUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVhPGfSRH3ea",
        "colab_type": "text"
      },
      "source": [
        "### 2 Includes and data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0HMYAyDIcQo",
        "colab_type": "code",
        "outputId": "6504966d-50f0-4a7e-8de8-87a8a572d50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "from typing import List, Set, Dict, Tuple, Optional\n",
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import math\n",
        "from datetime import date\n",
        "from math import floor\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "\n",
        "import category_encoders as ce\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools.eval_measures import mse as mse\n",
        "#from statsmodels.multivariate.pca import PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import numpy as np\n",
        "import skcuda.linalg as linalg\n",
        "from skcuda.linalg import PCA as cuPCA\n",
        "\n",
        "\n",
        "file_prefix = './data/'\n",
        "\n",
        "### Load the datasets from disk\n",
        "itemCategories=pd.read_csv(file_prefix + 'item_categories.csv')\n",
        "shops=pd.read_csv(file_prefix + 'shops.csv')\n",
        "test=pd.read_csv(file_prefix + 'test.csv')\n",
        "sales_original = pd.read_csv(file_prefix + 'sales_train.csv')\n",
        "\n",
        "items = pd.read_csv(file_prefix + 'items.csv')\n",
        "items = items.drop('item_name', axis = 1)\n",
        "items.set_index('item_id', inplace = True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.14 s, sys: 61.8 ms, total: 1.2 s\n",
            "Wall time: 1.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4kwx0ECH_Cg",
        "colab_type": "text"
      },
      "source": [
        "### 3 Data Cleaning, Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHgA59oIH1O5",
        "colab_type": "code",
        "outputId": "1a92e59a-625b-4c90-fb97-04a0f10677e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "SPAN = 5\n",
        "sales = sales_original.copy()\n",
        "\n",
        "def build(lo, hi): # [lo, hi)\n",
        "  data = sales[\n",
        "      (sales.date_block_num < hi) & (sales.date_block_num >= lo)\n",
        "    ].groupby(['date_block_num', 'shop_id', 'item_id']).agg(\n",
        "      sold = pd.NamedAgg(column = 'item_cnt_day', aggfunc = 'sum'),\n",
        "      price = pd.NamedAgg(column = 'item_price', aggfunc = 'first')\n",
        "    )\n",
        "  data.reset_index(drop = False, inplace = True)\n",
        "  \n",
        "  ## Append item_id category variable from the other dataset\n",
        "  data.set_index('item_id', drop = True, inplace = True)\n",
        "  data = data.join(items, on = 'item_id')\n",
        "  data.reset_index(inplace = True, drop = False)\n",
        "\n",
        "\n",
        "  ### append historic data for up to SPAN months before\n",
        "  aggs = data.copy()\n",
        "  aggs.drop(inplace = True, columns = ['item_category_id'])\n",
        "  aggs.rename(columns = {'date_block_num': 'date_block_before'}, inplace = True)\n",
        "  aggs.set_index(\n",
        "      ['item_id', 'shop_id', 'date_block_before'], inplace = True, drop = True)\n",
        "\n",
        "  for it in range(1, SPAN + 1):\n",
        "    data['date_block_before'] = data.date_block_num - it\n",
        "    ## Here is where we filter for the first month/s to always have all features\n",
        "    ## (some features are computed back in time, eg. last month's price)\n",
        "    data = data[data.date_block_before >= 0]\n",
        "    data = data.join(\n",
        "        aggs,\n",
        "        on = ['item_id', 'shop_id', 'date_block_before'],\n",
        "        rsuffix = ('_' + str(it))\n",
        "    )\n",
        "    data.drop('date_block_before', axis = 1, inplace = True)\n",
        "\n",
        "    #### Some combinations of shop-item have 0 sales in some months\n",
        "    ## those items that haven't had any sales in the given slots are assigned 0\n",
        "    ## instead of NaN\n",
        "    data['sold_' + str(it)] = data['sold_' + str(it)].fillna(0)\n",
        "    ## If the price wasn't present at the time:\n",
        "    ##   - first, fill backwards in time the last price (works with multiple prices)\n",
        "    ##   - then fill front\n",
        "    data['price_' + str(it)] = data['price_' + str(it)].fillna(method = 'backfill')\n",
        "    data['price_' + str(it)] = data['price_' + str(it)].fillna(method = 'ffill')\n",
        "    data['price_' + str(it) + '_log'] = np.log(data['price_' + str(it)].values)\n",
        "    data = data.drop('price_' + str(it), axis = 1)\n",
        "  data['price_log'] = np.log(data['price'].values)\n",
        "\n",
        "  data = data.drop(['date_block_num'], axis = 1)\n",
        "  data.reset_index(inplace = True, drop = True)\n",
        "  return data"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 53 ms, sys: 2.09 ms, total: 55.1 ms\n",
            "Wall time: 54.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cuOJa17XDQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "66b365ba-9270-427d-e23c-3911302b38f2"
      },
      "source": [
        "%%time\n",
        "## Separate and clean the data\n",
        "\n",
        "df = build(0, 32)\n",
        "cv = build(32 - SPAN, 33)\n",
        "\n",
        "### Encoding\n",
        "\n",
        "## One-hot-encoding for item_id, shop_id, item_category_id\n",
        "## drop_invariant has to be True\n",
        "##    it means the constant columns will be dropped\n",
        "##    this will prevent the normal equations from failing - the matrix won't\n",
        "##    be singular\n",
        "enc = ce.BinaryEncoder(cols=['item_id', 'shop_id', 'item_category_id'],\n",
        "                           drop_invariant = True)\n",
        "enc.fit(df.loc[:, df.columns != 'sold'], df.sold)\n",
        "X_enc = enc.transform(df.loc[:, df.columns != 'sold'])\n",
        "Y_enc = df.sold\n",
        "\n",
        "\n",
        "X_cv_enc = enc.transform(cv.loc[:, cv.columns != 'sold'])\n",
        "Y_cv_enc = cv.sold\n",
        "\n",
        "\n",
        "## PCA\n",
        "#pca = cuPCA(epsilon = 1e-2)\n",
        "#X_gpu = gpuarray.GPUArray(X_enc.shape, np.float64, order=\"F\")\n",
        "#X_gpu.set(X_enc.values)\n",
        "#Tmp_gpu = pca.fit_transform(X_gpu)\n",
        "#X = Tmp_gpu.get()\n",
        "\n",
        "pca = PCA(n_components = 4)\n",
        "pca.fit(X_enc)\n",
        "\n",
        "\n",
        "X = pca.transform(X_enc)\n",
        "X_cv = pca.transform(X_cv_enc)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 18.8 s, sys: 4.03 s, total: 22.8 s\n",
            "Wall time: 16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWb9HugPSiIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "624eaf9c-f8b8-45bf-e9f6-2b8ed6baec75"
      },
      "source": [
        "%%time\n",
        "## Model building\n",
        "\n",
        "X = sm.add_constant(X) ## add offset\n",
        "\n",
        "model = sm.OLS(Y_enc, X).fit()\n",
        "predictions = model.predict(X) \n",
        "\n",
        "print_model = model.summary()\n",
        "print(print_model)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                   sold   R-squared:                       0.540\n",
            "Model:                            OLS   Adj. R-squared:                  0.540\n",
            "Method:                 Least Squares   F-statistic:                 3.671e+05\n",
            "Date:                Wed, 06 May 2020   Prob (F-statistic):               0.00\n",
            "Time:                        00:29:57   Log-Likelihood:            -4.0254e+06\n",
            "No. Observations:             1252845   AIC:                         8.051e+06\n",
            "Df Residuals:                 1252840   BIC:                         8.051e+06\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          2.3015      0.005    428.367      0.000       2.291       2.312\n",
            "x1             0.0001   3.39e-06     43.922      0.000       0.000       0.000\n",
            "x2             0.3985      0.000   1166.182      0.000       0.398       0.399\n",
            "x3            -0.2526      0.001   -289.574      0.000      -0.254      -0.251\n",
            "x4             0.1626      0.001    150.055      0.000       0.161       0.165\n",
            "==============================================================================\n",
            "Omnibus:                  3871643.815   Durbin-Watson:                   1.668\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):    2255641789252.047\n",
            "Skew:                          46.854   Prob(JB):                         0.00\n",
            "Kurtosis:                    6575.762   Cond. No.                     1.58e+03\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.58e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "CPU times: user 1.03 s, sys: 1.17 s, total: 2.2 s\n",
            "Wall time: 693 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkvUpnC3HOZG",
        "colab_type": "text"
      },
      "source": [
        "### 4 Model Checking - Cross Validation and other\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTKaZLEvSlDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_cv = sm.add_constant(X_cv)\n",
        "Y_cv = Y_cv_enc\n",
        "predictions = model.predict(X_cv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyHgM6P4Y3QO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c3d9b91-476b-4ef3-9474-17292a783a53"
      },
      "source": [
        "## PCA - only 4 components, R^2-adj is 540\n",
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.624926192000991, 78.54915343910456)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNZAx3EqYh_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4666ca64-f0ca-431c-8882-511c30137b6e"
      },
      "source": [
        "pca.explained_variance_ratio_ # all components"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.99859051e-01, 9.85166431e-05, 1.51216558e-05, 9.79375766e-06,\n",
              "       7.46016112e-06, 5.60831288e-06, 1.15757877e-06, 2.41604750e-07,\n",
              "       1.83186207e-07, 1.66403712e-07, 1.53900981e-07, 1.52972389e-07,\n",
              "       1.51264111e-07, 1.47962390e-07, 1.20384548e-07, 1.18147362e-07,\n",
              "       1.11373490e-07, 1.07894802e-07, 1.04913257e-07, 1.03871595e-07,\n",
              "       1.03048679e-07, 1.01921543e-07, 9.98800932e-08, 9.77417958e-08,\n",
              "       9.58727256e-08, 9.49792107e-08, 9.01568247e-08, 8.84309143e-08,\n",
              "       8.65652209e-08, 8.27019133e-08, 8.06994078e-08, 7.94830824e-08,\n",
              "       7.56971747e-08, 5.16895265e-08, 4.67880647e-08, 4.14043426e-08,\n",
              "       3.93009606e-08, 3.47002729e-08, 2.69710588e-08, 9.10177329e-09])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_f_ztWUYZx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f59e31e-b213-4199-e983-f07764634c8e"
      },
      "source": [
        "## PCA with all components, R^2- adj 545\n",
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.62031692576499, 78.54915343910456)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rhoYfd_GLD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76561d5b-ee9e-4e11-c8dd-841430a87809"
      },
      "source": [
        "## PCA with 12 components, R^2- adj 544\n",
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.631935077264021, 78.54915343910456)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_L6gHezQcXO",
        "colab_type": "code",
        "outputId": "bf89598d-351d-44ef-81cb-c4679865d223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17.165870950393856, 78.54915343910456)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cErWmbjNDfd",
        "colab_type": "code",
        "outputId": "5d87a6d9-cf9d-4834-bcd2-5b3ce605a9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17.166284993830292, 78.54915343910456)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9V7Xo5JSpo1",
        "colab_type": "code",
        "outputId": "57667092-3c8b-42de-f24a-1b33298d7995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "math.sqrt(mse(predictions, Y_cv)), model.mse_total"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17.156509971134057, 73.88989502150442)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZazxAXqES8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.matshow(df.loc[:, df.columns.isin(['price_log', 'price_1_log', 'sold_1', 'sold_2', 'sold_3', 'price_2_log', 'sold'])].corr())\n",
        "#plt.show()\n",
        "\n",
        "sns.pairplot(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwh61ecDHZRQ",
        "colab_type": "text"
      },
      "source": [
        "### Extra: Random code bits\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2POnvLxSuZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## don't delete, this unstack idea is top shit and will be needed for sure\n",
        "def agg_months_as_columns(sales):\n",
        "  df['month'] = df.time.dt.month\n",
        "  df = pd.DataFrame(sales.groupby(['month', 'shop_id', 'item_id', \\\n",
        "                                   'item_price'])['item_cnt_day'].sum())\n",
        "  df = df.unstack(level = 0)\n",
        "  df = df.fillna(0)\n",
        "  df.columns = df.columns.get_level_values(1)\n",
        "  df.reset_index(drop = False, inplace = True)\n",
        "  df.columns = ['shop_id', 'item_price','Jan', 'Feb',\\\n",
        "                'Mar',  'Apr', 'May',  'Jun', 'Jul',  \\\n",
        "                'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "  return df\n",
        "\n",
        "### Forward selection with statsmodels\n",
        "def forward_selected(data, response):\n",
        "    \"\"\"Linear model designed by forward selection.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : pandas DataFrame with all possible predictors and response\n",
        "\n",
        "    response: string, name of response column in data\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    model: an \"optimal\" fitted statsmodels linear model\n",
        "           with an intercept\n",
        "           selected by forward selection\n",
        "           evaluated by adjusted R-squared\n",
        "    \"\"\"\n",
        "    remaining = set(data.columns)\n",
        "    remaining.remove(response)\n",
        "    selected = []\n",
        "    current_score, best_new_score = 0.0, 0.0\n",
        "    while remaining and current_score == best_new_score:\n",
        "        scores_with_candidates = []\n",
        "        for candidate in remaining:\n",
        "            formula = \"{} ~ {} + 1\".format(response,\n",
        "                                           ' + '.join(selected + [candidate]))\n",
        "            score = smf.ols(formula, data).fit().rsquared_adj\n",
        "            scores_with_candidates.append((score, candidate))\n",
        "        scores_with_candidates.sort()\n",
        "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
        "        if current_score < best_new_score:\n",
        "            remaining.remove(best_candidate)\n",
        "            selected.append(best_candidate)\n",
        "            current_score = best_new_score\n",
        "    formula = \"{} ~ {} + 1\".format(response,\n",
        "                                   ' + '.join(selected))\n",
        "    model = smf.ols(formula, data).fit()\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}