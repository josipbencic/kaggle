{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josipbencic/kaggle/blob/master/predict_future_sales_kristijan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qha1WQzF1Gh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1bdd5226-a52b-42e6-980d-35fa76b53454"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "PROJECT_PATH = \"/content/drive/My Drive/kaggle_tmp\"\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "\n",
        "GIT_TOKEN = \"097309d50a5b76d973c1011b2194720f119234c8\"\n",
        "GIT_USERNAME = \"josipbencic\"\n",
        "GIT_REPOSITORY = \"kaggle\"\n",
        "\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "\n",
        "!git clone \"{GIT_PATH}\" ./temp      # clone github repository to temp folder\n",
        "!cp -R ./temp/* \"{PROJECT_PATH}\"    # move all files/folders in temp folder to folder defined in project path\n",
        "!rm -rf ./temp                      # remove all the files/folders in temp folder\n",
        "#!rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./   # use remote sync to copy from google drive to local runtime google colab\n",
        "                                                     # but exclude data folder                                          \n",
        "!rsync -aP \"{PROJECT_PATH}\"/* ./  \n",
        "\n",
        "!pip install category_encoders\n",
        "!pip install pycuda\n",
        "!pip install scikit-cuda\n",
        "!pip install tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Cloning into './temp'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 59 (delta 25), reused 22 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n",
            "sending incremental file list\n",
            "README.md\n",
            "            605 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=11/12)\n",
            "environment.yml\n",
            "            211 100%  206.05kB/s    0:00:00 (xfr#2, to-chk=10/12)\n",
            "predict_future_sales_josip.ipynb\n",
            "         28,066 100%   26.77MB/s    0:00:00 (xfr#3, to-chk=9/12)\n",
            "predict_future_sales_kristijan.ipynb\n",
            "         11,405 100%    5.44MB/s    0:00:00 (xfr#4, to-chk=8/12)\n",
            "template.ipynb\n",
            "         11,516 100%    5.49MB/s    0:00:00 (xfr#5, to-chk=7/12)\n",
            "data/\n",
            "data/item_categories.csv\n",
            "          3,573 100%    1.14MB/s    0:00:00 (xfr#6, to-chk=5/12)\n",
            "data/items.csv\n",
            "      1,568,417 100%  135.98MB/s    0:00:00 (xfr#7, to-chk=4/12)\n",
            "data/sales_train.csv\n",
            "     94,603,866 100%  196.99MB/s    0:00:00 (xfr#8, to-chk=3/12)\n",
            "data/sample_submission.csv\n",
            "      2,245,108 100%    4.56MB/s    0:00:00 (xfr#9, to-chk=2/12)\n",
            "data/shops.csv\n",
            "          2,977 100%    6.19kB/s    0:00:00 (xfr#10, to-chk=1/12)\n",
            "data/test.csv\n",
            "      3,182,735 100%    6.25MB/s    0:00:00 (xfr#11, to-chk=0/12)\n",
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.4)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.12.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n",
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/3f/5658c38579b41866ba21ee1b5020b8225cec86fe717e4b1c5c972de0a33c/pycuda-2019.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 2.8MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/4c/a04ed1882ae0fd756b787be4d0f15d81c137952d83cf9b991bba0bbb54ba/pytools-2020.2.tar.gz (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/78/f6ade1e18aebda570eed33b7c534378d9659351cadce2fcbc7b31be5f615/Mako-1.1.2-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2019.1.2-cp36-cp36m-linux_x86_64.whl size=4537027 sha256=b38398df45aff892b2e146057d00ced2f5c6ac2f6f45ee8f8e4accc425d89763\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/60/f0/b1c430c73d281ac3e46070480db50f7907364eb6f6d3188396\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.2-py2.py3-none-any.whl size=62338 sha256=16fd48eefa61a178bb304a89468ea94ad974e1a7fef616729c82189112f8e534\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/d6/ac/03a67d071bde6d272d1f7c9ab7f4344fa9d7b9d98bda7fd127\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.2 pycuda-2019.1.2 pytools-2020.2\n",
            "Collecting scikit-cuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/8b/36d178c3b98524fe5b1cc15d075d34e2e6e291c4b0461f6e901f1e0bc736/scikit_cuda-0.5.3-py2.py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycuda>=2016.1 in /usr/local/lib/python3.6/dist-packages (from scikit-cuda) (2019.1.2)\n",
            "Requirement already satisfied: mako>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-cuda) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-cuda) (1.18.4)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda>=2016.1->scikit-cuda) (4.4.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.6/dist-packages (from pycuda>=2016.1->scikit-cuda) (2020.2)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pycuda>=2016.1->scikit-cuda) (1.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako>=1.0.1->scikit-cuda) (1.1.1)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda>=2016.1->scikit-cuda) (1.12.0)\n",
            "Installing collected packages: scikit-cuda\n",
            "Successfully installed scikit-cuda-0.5.3\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.29.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfSNTbsubkw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "2abe9d12-a921-4e47-aeca-fe29090a6740"
      },
      "source": [
        "## Inspect collab machine\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=fdd954aa6d6ec22da85405cd9e28c81f94c80fd062fd9d6eb08108ddac5f5033\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 159.0 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYOxgaFibk8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "886e301c-2203-4975-d02b-763a47518776"
      },
      "source": [
        "%%time\n",
        "from typing import List, Set, Dict, Tuple, Optional\n",
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import math\n",
        "from datetime import date\n",
        "from math import floor\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "\n",
        "import category_encoders as ce\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools.eval_measures import mse as mse\n",
        "#from statsmodels.multivariate.pca import PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import numpy as np\n",
        "import skcuda.linalg as linalg\n",
        "from skcuda.linalg import PCA as cuPCA\n",
        "\n",
        "\n",
        "file_prefix = './data/'\n",
        "\n",
        "### Load the datasets from disk\n",
        "itemCategories=pd.read_csv(file_prefix + 'item_categories.csv')\n",
        "shops=pd.read_csv(file_prefix + 'shops.csv')\n",
        "test=pd.read_csv(file_prefix + 'test.csv')\n",
        "sales_original = pd.read_csv(file_prefix + 'sales_train.csv')\n",
        "\n",
        "items = pd.read_csv(file_prefix + 'items.csv')\n",
        "items = items.drop('item_name', axis = 1)\n",
        "items.set_index('item_id', inplace = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d9c79441f5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from typing import List, Set, Dict, Tuple, Optional\\nimport argparse\\nimport sys\\nimport os\\nimport csv\\nimport time\\nimport math\\nfrom datetime import date\\nfrom math import floor\\n\\nimport numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport matplotlib.dates as mdates\\nfrom pandas.plotting import register_matplotlib_converters\\nregister_matplotlib_converters()\\n\\nimport category_encoders as ce\\nimport statsmodels.api as sm\\nfrom statsmodels.tools.eval_measures import mse as mse\\n#from statsmodels.multivariate.pca import PCA\\nfrom sklearn.decomposition import PCA\\n\\nimport pycuda.autoinit\\nimport pycuda.gpuarray as gpuarray\\nimport numpy as np\\nimport skcuda.linalg as linalg\\nfrom skcuda.linalg import PCA as cuPCA\\n\\n\\nfile_prefix = './data/'\\n\\n### Load the datasets from disk\\nitemCategories=pd.read_csv(file_prefix + 'item_categories.csv')\\nshops=pd.read_csv(file_prefix + 'shops.csv')\\ntest=pd.read_csv(file_prefix + 'test.csv')\\nsales_original = pd.read_csv(file_prefix + 'sales_train.csv')\\n\\nitems = pd.read_csv(file_prefix + 'items.csv')\\nitems = items.drop('item_name', axis = 1)\\nitems.set_index('item_id', inplace = True)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hQU4PP-xr2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "SPAN = 5\n",
        "sales = sales_original.copy()\n",
        "\n",
        "def build(lo, hi): # [lo, hi)\n",
        "  data = sales[\n",
        "      (sales.date_block_num < hi) & (sales.date_block_num >= lo)\n",
        "    ].groupby(['date_block_num', 'shop_id', 'item_id']).agg(\n",
        "      sold = pd.NamedAgg(column = 'item_cnt_day', aggfunc = 'sum'),\n",
        "      price = pd.NamedAgg(column = 'item_price', aggfunc = 'first')\n",
        "    )\n",
        "  data.reset_index(drop = False, inplace = True)\n",
        "  \n",
        "  ## Append item_id category variable from the other dataset\n",
        "  data.set_index('item_id', drop = True, inplace = True)\n",
        "  data = data.join(items, on = 'item_id')\n",
        "  data.reset_index(inplace = True, drop = False)\n",
        "\n",
        "\n",
        "  ### append historic data for up to SPAN months before\n",
        "  aggs = data.copy()\n",
        "  aggs.drop(inplace = True, columns = ['item_category_id'])\n",
        "  aggs.rename(columns = {'date_block_num': 'date_block_before'}, inplace = True)\n",
        "  aggs.set_index(\n",
        "      ['item_id', 'shop_id', 'date_block_before'], inplace = True, drop = True)\n",
        "\n",
        "  for it in range(1, SPAN + 1):\n",
        "    data['date_block_before'] = data.date_block_num - it\n",
        "    ## Here is where we filter for the first month/s to always have all features\n",
        "    ## (some features are computed back in time, eg. last month's price)\n",
        "    data = data[data.date_block_before >= 0]\n",
        "    data = data.join(\n",
        "        aggs,\n",
        "        on = ['item_id', 'shop_id', 'date_block_before'],\n",
        "        rsuffix = ('_' + str(it))\n",
        "    )\n",
        "    data.drop('date_block_before', axis = 1, inplace = True)\n",
        "\n",
        "    #### Some combinations of shop-item have 0 sales in some months\n",
        "    ## those items that haven't had any sales in the given slots are assigned 0\n",
        "    ## instead of NaN\n",
        "    data['sold_' + str(it)] = data['sold_' + str(it)].fillna(0)\n",
        "    ## If the price wasn't present at the time:\n",
        "    ##   - first, fill backwards in time the last price (works with multiple prices)\n",
        "    ##   - then fill front\n",
        "    data['price_' + str(it)] = data['price_' + str(it)].fillna(method = 'backfill')\n",
        "    data['price_' + str(it)] = data['price_' + str(it)].fillna(method = 'ffill')\n",
        "    data['price_' + str(it) + '_log'] = np.log(data['price_' + str(it)].values)\n",
        "    data = data.drop('price_' + str(it), axis = 1)\n",
        "  data['price_log'] = np.log(data['price'].values)\n",
        "\n",
        "  data = data.drop(['date_block_num'], axis = 1)\n",
        "  data.reset_index(inplace = True, drop = True)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZwOLpXPF2AE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "## Separate and clean the data\n",
        "\n",
        "df = build(0, 32)\n",
        "cv = build(32 - SPAN, 33)\n",
        "\n",
        "### Encoding\n",
        "\n",
        "## One-hot-encoding for item_id, shop_id, item_category_id\n",
        "## drop_invariant has to be True\n",
        "##    it means the constant columns will be dropped\n",
        "##    this will prevent the normal equations from failing - the matrix won't\n",
        "##    be singular\n",
        "enc = ce.BinaryEncoder(cols=['item_id', 'shop_id', 'item_category_id'],\n",
        "                           drop_invariant = True)\n",
        "enc.fit(df.loc[:, df.columns != 'sold'], df.sold)\n",
        "X_enc = enc.transform(df.loc[:, df.columns != 'sold'])\n",
        "Y_enc = df.sold\n",
        "\n",
        "\n",
        "X_cv_enc = enc.transform(cv.loc[:, cv.columns != 'sold'])\n",
        "Y_cv_enc = cv.sold\n",
        "\n",
        "\n",
        "## PCA\n",
        "#pca = cuPCA(epsilon = 1e-2)\n",
        "#X_gpu = gpuarray.GPUArray(X_enc.shape, np.float64, order=\"F\")\n",
        "#X_gpu.set(X_enc.values)\n",
        "#Tmp_gpu = pca.fit_transform(X_gpu)\n",
        "#X = Tmp_gpu.get()\n",
        "\n",
        "pca = PCA(n_components = 4)\n",
        "pca.fit(X_enc)\n",
        "\n",
        "\n",
        "X = pca.transform(X_enc)\n",
        "X_cv = pca.transform(X_cv_enc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2yY9jmCeYRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_variable(shape, w=0.1):\n",
        "  initial = tf.truncated_normal(shape, stddev=w)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape, w=0.1):\n",
        "  initial = tf.constant(w, shape=shape)\n",
        "  return tf.Variable(initial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALcPDTfUeZuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indim=trainx.shape[1]\n",
        "l1=10\n",
        "outp=1\n",
        "W1=weight_variable([indim,l1])\n",
        "W2=weight_variable([l1,outp])\n",
        "\n",
        "b1=bias_variable([l1])\n",
        "b2=bias_variable([outp])\n",
        "\n",
        "x=tf.placeholder(tf.float32,[None,indim],name=\"input\")\n",
        "y=tf.placeholder(tf.float32,[None,outp],name=\"output\")\n",
        "\n",
        "trainep=1000\n",
        "\n",
        "model1=tf.nn.relu(tf.matmul(x,W1)+b1)\n",
        "model2=tf.sigmoid(tf.matmul(model1,W2)+b2)\n",
        "\n",
        "loss=tf.reduce_sum(tf.square(model2-y))\n",
        "\n",
        "train=tf.train.GradientDescentOptimizer(1).minimize(loss)\n",
        "\n",
        "\n",
        "init=tf.global_variables_initializer()\n",
        "sess=tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for i in range (trainep):       #ustekas input i output i pustis da trenira\n",
        "  sess.run(train,feed_dict={x:X, y:Y_enc })\n",
        "  l=sess.run(loss,feed_dict={x:X, y:Y_enc })\n",
        "  print(l)\n",
        "sess.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}